<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research - Jason Sun</title>
    <meta name="description" content="Research experience and current projects in AI, robotics, and human-computer interaction.">
    
    <!-- Fonts & Icons -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Styles -->
    <link rel="stylesheet" href="styles_multipage.css">
</head>
<body>
    
    <!-- Navigation -->
    <nav class="nav">
        <div class="nav-container">
            <a href="index.html" class="nav-brand">Jason Sun</a>
            <div class="nav-links">
                <a href="index.html" class="nav-link">Home</a>
                <a href="research.html" class="nav-link active">Research</a>
                <a href="industry.html" class="nav-link">Industry</a>
                <a href="projects.html" class="nav-link">Projects</a>
                <a href="publications.html" class="nav-link">Publications</a>
                <a href="cv.pdf" class="nav-link">CV</a>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
        <div class="container">
            <h1 class="page-title">Research Experience</h1>
            
            <!-- Current Research -->
            <section class="content-section">
                <div class="section-label">CURRENT RESEARCH</div>
                
                <div class="research-item">
                    <div class="research-header">
                        <h3>AI-Driven Intelligence Systems for Professional Sports</h3>
                        <div class="research-meta">
                            <span>JHU Sports Analytics Research Group</span>
                            <span>Aug 2024 - Present</span>
                        </div>
                    </div>
                    <div class="research-advisor">Advisor: Prof. Anton Dahbura</div>
                    <div class="research-description">
                        <p>
                            Leading the development of AI systems for NFL and MLB teams. Built an on-premise RAG-LLM system 
                            for the Baltimore Ravens that processes 40,000+ articles covering 2,000 prospects, reducing 
                            research time by 65% while preserving analyst judgment for strategic decisions.
                        </p>
                        <p>
                            Developed BatVision, a computer vision pipeline for the Baltimore Orioles using regression-calibrated 
                            deep learning to analyze baseball equipment with sub-millimeter precision.
                        </p>
                    </div>
                    <div class="research-tags">
                        <span class="tag">LLMs</span>
                        <span class="tag">RAG</span>
                        <span class="tag">Computer Vision</span>
                        <span class="tag">Sports Analytics</span>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-header">
                        <h3>Multilingual Multimodal Cultural Alignment</h3>
                        <div class="research-meta">
                            <span>CLSP, Johns Hopkins University</span>
                            <span>Sep 2024 - Present</span>
                        </div>
                    </div>
                    <div class="research-advisor">Advisors: Dr. Kenton Murray, Prof. Ziang Xiao</div>
                    <div class="research-description">
                        <p>
                            Investigating how text-to-image models encode and perpetuate cultural biases when serving 
                            global populations. Building comprehensive evaluation frameworks to measure whether generative 
                            models produce culturally authentic representations across diverse linguistic communities.
                        </p>
                    </div>
                    <div class="research-tags">
                        <span class="tag">Vision-Language Models</span>
                        <span class="tag">Cultural AI</span>
                        <span class="tag">Bias Evaluation</span>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-header">
                        <h3>Adaptive Teleoperation for Surgical Robotics</h3>
                        <div class="research-meta">
                            <span>SMARTS Lab, Johns Hopkins University</span>
                            <span>Oct 2024 - Present</span>
                        </div>
                    </div>
                    <div class="research-advisor">Advisors: Prof. Peter Kazanzides, Dr. Adnan Munawar</div>
                    <div class="research-description">
                        <p>
                            Developing human-performance-aware teleoperation systems that adapt motion scaling based on 
                            surgeon expertise and task complexity. System optimizes precision while maintaining surgeon 
                            agency in critical procedures.
                        </p>
                    </div>
                    <div class="research-tags">
                        <span class="tag">Surgical Robotics</span>
                        <span class="tag">Teleoperation</span>
                        <span class="tag">Human-Robot Interaction</span>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-header">
                        <h3>Vision-Language Models for Robot Learning</h3>
                        <div class="research-meta">
                            <span>Intuitive Computing Lab, Johns Hopkins University</span>
                            <span>Sep 2024 - Present</span>
                        </div>
                    </div>
                    <div class="research-advisor">Advisor: Prof. Chien-Ming Huang</div>
                    <div class="research-description">
                        <p>
                            Creating GUIDES framework using instructor-distilled embeddings for robot policy enhancement. 
                            Achieved 40% improvement in task success rates through multimodal guidance systems that 
                            enable robots to learn from human demonstrations more effectively.
                        </p>
                    </div>
                    <div class="research-tags">
                        <span class="tag">Robot Learning</span>
                        <span class="tag">VLMs</span>
                        <span class="tag">Embodied AI</span>
                    </div>
                </div>
            </section>

            <!-- Past Research -->
            <section class="content-section">
                <div class="section-label">PAST RESEARCH</div>
                
                <div class="research-item">
                    <div class="research-header">
                        <h3>Cooperative Control of Legged Millirobots</h3>
                        <div class="research-meta">
                            <span>UC Berkeley Biomimetic Millisystems Lab</span>
                            <span>Apr 2023 - May 2024</span>
                        </div>
                    </div>
                    <div class="research-advisor">Advisor: Prof. Ronald S. Fearing</div>
                    <div class="research-description">
                        <p>
                            Researched efficient model-based learning for cooperative control using Model Predictive Control 
                            and Deep Reinforcement Learning. Developed ROS pipeline for real-time multi-robot tracking, 
                            achieving 100x improvement in sample efficiency and 5x reduction in hardware costs.
                        </p>
                    </div>
                    <div class="research-tags">
                        <span class="tag">Microrobotics</span>
                        <span class="tag">MPC</span>
                        <span class="tag">Multi-Robot Systems</span>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-header">
                        <h3>Visual Navigation in Novel Environments</h3>
                        <div class="research-meta">
                            <span>Berkeley AI Research Lab (BAIR)</span>
                            <span>Apr 2023 - Jan 2024</span>
                        </div>
                    </div>
                    <div class="research-advisor">Advisor: Prof. S. Shankar Sastry</div>
                    <div class="research-description">
                        <p>
                            Collaborated with Prof. Bansal at USC on combining optimal control and learning for visual 
                            navigation. Improved CNN perception module with frame stacking and Dataset Aggregation (Dagger) 
                            for enhanced efficiency.
                        </p>
                    </div>
                    <div class="research-tags">
                        <span class="tag">Visual Navigation</span>
                        <span class="tag">Deep Learning</span>
                        <span class="tag">SLAM</span>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-header">
                        <h3>AI-Driven Audio-Visual Content Generation</h3>
                        <div class="research-meta">
                            <span>Center for New Music and Audio Technologies (CNMAT)</span>
                            <span>Aug 2023 - Dec 2023</span>
                        </div>
                    </div>
                    <div class="research-advisor">Advisor: Prof. Edmund Campion</div>
                    <div class="research-description">
                        <p>
                            Developed a video generation system using stable diffusion and AI-driven music analysis for 
                            dynamic audio-visual content. Presented the project at a Berkeley concert, enhancing audience 
                            engagement with dynamic AI-generated visuals.
                        </p>
                    </div>
                    <div class="research-tags">
                        <span class="tag">Generative AI</span>
                        <span class="tag">Audio Processing</span>
                        <span class="tag">Creative AI</span>
                    </div>
                </div>
            </section>
        </div>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>© 2025 Xiaojian Sun • Baltimore, MD</p>
        </div>
    </footer>

    <script src="script_multipage.js"></script>
</body>
</html>